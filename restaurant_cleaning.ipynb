{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a78c67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Load the original CSV file\n",
    "csv_file_path = r\"C:\\Professional\\MS\\SHU\\Dissertation\\Input_data\\restaurants.csv\"\n",
    "\n",
    "input_data_df = pd.read_csv(csv_file_path,encoding ='utf-8')\n",
    "\n",
    "\n",
    "input_data_df\n",
    "\n",
    "df_req = input_data_df[['name','score','ratings','category','price_range','zip_code']]\n",
    "\n",
    "df_req['price_range'] = df_req['price_range'].apply(lambda x: 1 if x == '$' else (2 if x == '$$' else (3 if x == '$$$' else (4 if x == '$$$$' else 99))))\n",
    "\n",
    "\n",
    "\n",
    "# Split the category column into separate elements\n",
    "df_req['category'] = df_req['category'].str.split(', ')\n",
    "df_req =df_req.explode('category')\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary mapping major cuisines to categories\n",
    "cuisine_to_category = {\n",
    "    'Burgers': 'American',\n",
    "    'American': 'American',\n",
    "    'Sandwiches': 'Sandwiches',\n",
    "    'Coffee and Tea': 'Coffee and Tea',\n",
    "    'Breakfast and Brunch': 'Breakfast and Brunch',\n",
    "    'Bubble Tea': 'Coffee and Tea',\n",
    "    'Cheesesteak': 'American',\n",
    "    'Alcohol': 'Other',\n",
    "    'Pizza': 'Italian',\n",
    "    'Seafood': 'Seafood',\n",
    "    'Sushi': 'Japanese',\n",
    "    'Steak': 'American',\n",
    "    'Asian': 'Asian',\n",
    "    'Japanese': 'Japanese',\n",
    "    'Vegetarian': 'Vegetarian',\n",
    "    'Asian Fusion': 'Asian',\n",
    "    'Chinese': 'Chinese',\n",
    "    'Indian': 'Indian',\n",
    "    'Healthy': 'Other',\n",
    "    'Fast Food': 'American',\n",
    "    'Fish and Chips': 'Seafood',\n",
    "    'Desserts': 'Desserts',\n",
    "    'Ice Cream + Frozen Yogurt': 'Desserts',\n",
    "    'Ice Cream & Frozen Yogurt': 'Desserts',\n",
    "    'Comfort Food': 'American',\n",
    "    'Diner': 'American',\n",
    "    'Chicken': 'Other',\n",
    "    'salad': 'Salads',\n",
    "    'Sandwich': 'Sandwiches',\n",
    "    'Family Meals': 'American',\n",
    "    'Pakistani': 'Indian',\n",
    "    'Indian Curry': 'Indian',\n",
    "    'Halal': 'Middle Eastern',\n",
    "    'Wings': 'American',\n",
    "    'Middle Eastern': 'Middle Eastern',\n",
    "    'Mediterranean': 'Mediterranean',\n",
    "    'Greek': 'Mediterranean',\n",
    "    'Juice and Smoothies': 'Juice and Smoothies',\n",
    "    'Fruit': 'Other',\n",
    "    'Caribbean': 'Caribbean',\n",
    "    'Cuban': 'Latin American',\n",
    "    'Drinks': 'Other',\n",
    "    'Bakery': 'Bakery',\n",
    "    'Italian': 'Italian',\n",
    "    'Exclusive to Eats': 'Other',\n",
    "    'Mexican': 'Mexican',\n",
    "    'Burritos': 'Mexican',\n",
    "    'BBQ': 'American',\n",
    "    'Black-owned': 'American',\n",
    "    'Salads': 'Salads',\n",
    "    'Hot Dog': 'American',\n",
    "    'Cafe': 'Coffee and Tea',\n",
    "    'Coffee & Tea': 'Coffee and Tea',\n",
    "    'Bowls': 'Asian',\n",
    "    'Vegan': 'Vegetarian',\n",
    "    'pizza': 'Italian',\n",
    "    'Deli': 'Sandwiches',\n",
    "    'Pasta': 'Italian',\n",
    "    'Soup': 'Chinese',\n",
    "    'Noodles': 'Asian',\n",
    "    'French': 'French',\n",
    "    'Cantonese': 'Chinese',\n",
    "    'Tacos': 'Mexican',\n",
    "    'Southern': 'American',\n",
    "    'Soul Food': 'American',\n",
    "    'New American': 'American',\n",
    "    'Latin American': 'Latin American',\n",
    "    'New Mexican': 'Mexican',\n",
    "    'Fried Chicken': 'American',\n",
    "    'Breakfast & Brunch': 'Breakfast and Brunch',\n",
    "    'Donuts': 'Desserts',\n",
    "    'Spanish': 'European',\n",
    "    'Bar Food': 'Other',\n",
    "    'Chicken Strips': 'American',\n",
    "    'Dinner': 'American',\n",
    "    'burger': 'American',\n",
    "    'wings': 'American',\n",
    "    'Japanese sweets': 'Japanese',\n",
    "    'Vegetarian Friendly': 'Vegetarian',\n",
    "    'Kids Friendly': 'Other',\n",
    "    'Family Friendly': 'Other',\n",
    "    'Group Friendly': 'Other',\n",
    "    'Asian Cuisine': 'Asian',\n",
    "    'Thai': 'Thai',\n",
    "    'Allergy Friendly': 'Other',\n",
    "    'Cajun': 'Other',\n",
    "    'Gluten Free': 'Other',\n",
    "    'Rolls': 'Japanese',\n",
    "    'pasta': 'Italian',\n",
    "    'Traditional American': 'American',\n",
    "    'Pharmacy': 'Other',\n",
    "    'Convenience': 'Other',\n",
    "    'Everyday Essentials': 'Other',\n",
    "    'Baby': 'Other',\n",
    "    'Dessert: Other': 'Desserts',\n",
    "    'Turkish': 'Turkish',\n",
    "    'PIzza': 'Italian',\n",
    "    'Pastry': 'Bakery',\n",
    "    'Tex Mex': 'Mexican',\n",
    "    'Wine': 'Other',\n",
    "    'Omelette': 'Breakfast and Brunch',\n",
    "    'Retail': 'Other',\n",
    "    'Gift Store': 'Other',\n",
    "    'Beauty Supply': 'Other',\n",
    "    'Barfood': 'Other',\n",
    "    'Snacks': 'Other',\n",
    "    'Creole': 'Other',\n",
    "    'Pretzel': 'Other',\n",
    "    'Fish & Seafood': 'Seafood',\n",
    "    'Ramen': 'Japanese',\n",
    "    'Juice': 'Juice and Smoothies',\n",
    "    'Korean': 'Korean',\n",
    "    'European': 'European',\n",
    "    'Plant Based': 'Vegetarian',\n",
    "    'Brazilian': 'Latin American',\n",
    "    'Dominican': 'Latin American',\n",
    "    'Flour based food': 'Bakery',\n",
    "    'Candy': 'Desserts',\n",
    "    'Sanwiches': 'Sandwiches',\n",
    "    'Cupcakes': 'Desserts',\n",
    "    'Vietnamese': 'Vietnamese',\n",
    "    'Dount': 'Desserts',\n",
    "    'Juice & Smoothies': 'Juice and Smoothies',\n",
    "    'Rice-bowls': 'Asian',\n",
    "    'Bagels': 'Bakery',\n",
    "    'Poke': 'Asian',\n",
    "    'Aus Burger': 'Australian',\n",
    "    'chocolatier': 'Desserts',\n",
    "    'Cajun / Creole': 'Other',\n",
    "    'Grocery': 'Other',\n",
    "    'Juice Bars': 'Juice and Smoothies',\n",
    "    'Flowers': 'Other',\n",
    "    'florist': 'Other',\n",
    "    'Gifts': 'Other',\n",
    "    'Plants': 'Other',\n",
    "    'Home & Personal Care': 'Other',\n",
    "    'Modern European': 'European',\n",
    "    'German': 'European',\n",
    "    'African': 'African',\n",
    "    'Jamaican': 'Caribbean',\n",
    "    'Egyptian': 'Middle Eastern',\n",
    "    'Asian-owned': 'Asian',\n",
    "    'Stir Fried': 'Asian',\n",
    "    'Teppanyaki': 'Japanese',\n",
    "    'Rice & Curry': 'Indian',\n",
    "    'Canadian': 'Canadian',\n",
    "    'Pub': 'Other',\n",
    "    'Polish': 'European',\n",
    "    'Rice Dishes': 'Asian',\n",
    "    'Fried Foods': 'Fast Food',\n",
    "    'Women-owned': 'Other',\n",
    "    'Arabian': 'Middle Eastern',\n",
    "    'Malaysian': 'Asian',\n",
    "    'Vegan Friendly': 'Vegetarian',\n",
    "    'African: Other': 'African',\n",
    "    'Mac and Cheese': 'American',\n",
    "    'Irish': 'European',\n",
    "    'Specialty Foods': 'Other',\n",
    "    'AAPI-owned': 'Asian',\n",
    "    'Chinese: Other': 'Chinese',\n",
    "    'Syrian': 'Middle Eastern',\n",
    "    'Pho': 'Vietnamese',\n",
    "    'Momos': 'Nepalese',\n",
    "    'Nepalese': 'Nepalese',\n",
    "    'Kosher': 'Other',\n",
    "    'Jewish': 'Other',\n",
    "    'Hawaiian': 'Hawaiian',\n",
    "    'Affordable Meals': 'American',\n",
    "    'Tempura': 'Japanese',\n",
    "    'Ethiopian': 'African',\n",
    "    'Crepe': 'French',\n",
    "    'Japanese set items': 'Japanese',\n",
    "    'Tamale': 'Latin American',\n",
    "    'Other': 'Other',\n",
    "    'Latin Fusion': 'Latin American',\n",
    "    'Gluten Free Friendly': 'Other',\n",
    "    'Falafel': 'Middle Eastern',\n",
    "    'Bar / Pub Food': 'Other',\n",
    "    'Cheese': 'Other',\n",
    "    'South American': 'Latin American',\n",
    "    'Salad/Sandwiches': 'Salads',\n",
    "    'Ice Cream': 'Desserts',\n",
    "    'Taiwanese': 'Asian',\n",
    "    'Local Specialities': 'Other',\n",
    "    'Venezuelan': 'Latin American',\n",
    "    'Colombian': 'Latin American',\n",
    "    'Salad / Sandwiches': 'Salads',\n",
    "    'Gourmet': 'Other',\n",
    "    'Biryani': 'Indian',\n",
    "    'Japanese: Sushi': 'Japanese',\n",
    "    'Russian': 'European',\n",
    "    'Breakfast': 'Breakfast and Brunch',\n",
    "    'Brunch': 'Breakfast and Brunch',\n",
    "    'Japanese Style curry': 'Japanese',\n",
    "    'Northeastern Thai': 'Thai',\n",
    "    'Tea & Coffee': 'Coffee and Tea',\n",
    "    'Dim Sum': 'Chinese',\n",
    "    'To Share': 'Other',\n",
    "    'Peruvian': 'Latin American',\n",
    "    'Tapas': 'Mexican',\n",
    "    'Southern Thai': 'Thai',\n",
    "    'Cakes': 'Desserts',\n",
    "    'Wraps': 'Sandwiches',\n",
    "    'Western': 'Other',\n",
    "    'Liquor Stores': 'Other',\n",
    "    'OrganicProducts': 'Other',\n",
    "    'Chinese: Cantonese': 'Chinese',\n",
    "    'Keto': 'Other',\n",
    "    'Hungarian': 'European',\n",
    "    'Vegetarian-Friendly': 'Vegetarian',\n",
    "    'Asian: Other': 'Asian',\n",
    "    'South East Asian': 'Asian',\n",
    "    'Gluten-Free Friendly': 'Other',\n",
    "    'Mongolian': 'Asian',\n",
    "    'Afghan': 'Middle Eastern',\n",
    "    'Japanese BBQ': 'Japanese',\n",
    "    'Street Food': 'Other',\n",
    "    'Lebanese': 'Middle Eastern',\n",
    "    'Chinese: Sichuan': 'Chinese',\n",
    "    'Braised Dishes': 'Asian',\n",
    "    'Braised Pork Rice': 'Asian',\n",
    "    'Szechuan': 'Chinese',\n",
    "    'Burmese': 'Asian',\n",
    "    'Japanese Skewer food': 'Japanese',\n",
    "    'Japanese: Other': 'Japanese',\n",
    "    'North Indian': 'Indian',\n",
    "    'Yakitori': 'Japanese',\n",
    "    'Empanada': 'Latin American',\n",
    "    'Hot Pot': 'Asian',\n",
    "    'Portuguese': 'European',\n",
    "    'Persian': 'Middle Eastern',\n",
    "    'MarketingCampaign': 'Other',\n",
    "    'whatever': 'Other',\n",
    "    'Chinese: Noodles & Dumplings': 'Chinese',\n",
    "    'Chinese Food': 'Chinese',\n",
    "    'Tibetan': 'Asian',\n",
    "    'South African': 'African',\n",
    "    'Indonesian': 'Asian',\n",
    "    'Açaí': 'Other',\n",
    "    'Beer': 'Other',\n",
    "    'Kebab': 'Middle Eastern',\n",
    "    'Chinese: Taiwanese': 'Chinese',\n",
    "    'Specialty': 'Other',\n",
    "    'Scandinavian': 'European',\n",
    "    'Tom Yum': 'Thai',\n",
    "    'Iranian': 'Middle Eastern',\n",
    "    'Spicy Hot Pot': 'Asian',\n",
    "    'Dumpling House': 'Chinese',\n",
    "    'Paleo': 'Other',\n",
    "    'South Indian': 'Indian',\n",
    "    'BOGO': 'Other',\n",
    "    'Bistro': 'European',\n",
    "    'Laotian': 'Asian',\n",
    "    'Modern French': 'French',\n",
    "    'Home & Decor': 'Other',\n",
    "    'Japanese: Ramen': 'Japanese',\n",
    "    'Northern Thai': 'Thai',\n",
    "    'Carnicería': 'Mexican',\n",
    "    'Australian': 'Australian',\n",
    "    'Filipino': 'Asian',\n",
    "    'Dumplings': 'Chinese',\n",
    "    'South Asian': 'Asian',\n",
    "    'Latin American: Other': 'Latin American',\n",
    "    'Himalayan': 'Asian',\n",
    "    'Convenience Store with Alcohol': 'Other',\n",
    "    'Smoke Shop': 'Other',\n",
    "    'Quesadillas': 'Mexican',\n",
    "    'Modern Australian': 'Australian',\n",
    "    'Bento': 'Japanese',\n",
    "    'Beef Noodles': 'Asian',\n",
    "    'Singaporean': 'Asian',\n",
    "    'Salvadorian': 'Latin American',\n",
    "    'Poutine': 'Canadian',\n",
    "    'Eastern European': 'European',\n",
    "    'Non Halal': 'Other',\n",
    "    'Moroccan': 'African',\n",
    "    'Yucatecan': 'Latin American',\n",
    "    'Cambodian': 'Asian',\n",
    "    'Swedish': 'European',\n",
    "    'Argentinian': 'Latin American',\n",
    "    'Vegan-Friendly': 'Vegetarian',\n",
    "    'Other Asian': 'Asian',\n",
    "    'Adult': 'Other',\n",
    "    'Western-style Japanese Food': 'Japanese',\n",
    "    'Congee': 'Asian',\n",
    "    'Sichuan': 'Chinese',\n",
    "    'Indoor Plants & Gifts': 'Other',\n",
    "    'bookstore': 'Other',\n",
    "    'West Indian': 'Caribbean',\n",
    "    'ButcherShop': 'Other',\n",
    "    'Arepa': 'Latin American',\n",
    "    'Georgian': 'European',\n",
    "    'Sandwhiches': 'Sandwiches',\n",
    "    'OtherAsian': 'Asian',\n",
    "    'Okonomiyaki': 'Japanese',\n",
    "    'Pure Veg': 'Vegetarian',\n",
    "    'Dosa': 'Indian',\n",
    "    'Pet Shop': 'Other',\n",
    "    'Pet Supplies': 'Other',\n",
    "    'pet supplies': 'Other',\n",
    "    'Otsumami': 'Japanese',\n",
    "    'British': 'European',\n",
    "    'Scottish': 'European',\n",
    "    'American (New)': 'American',\n",
    "    'Bacon': 'Other',\n",
    "    'Eggs': 'Breakfast and Brunch',\n",
    "    'Rotti': 'Indian',\n",
    "    'Chinese: Hot Pot': 'Chinese',\n",
    "    'West African': 'African',\n",
    "    'Armenian': 'European',\n",
    "    'Neapolitan': 'Italian',\n",
    "    'Bangladeshi': 'Indian',\n",
    "    'Congee Boil Rice': 'Asian',\n",
    "    'Gyro': 'Mediterranean',\n",
    "    'African: Ethiopian': 'African',\n",
    "    'Vegetarian / Vegan': 'Vegetarian',\n",
    "    'Belgian': 'European',\n",
    "    'Premium': 'Other',\n",
    "    'Personal Care': 'Other',\n",
    "    'Asado': 'Latin American',\n",
    "    'Health & Nutrition Supplements': 'Other',\n",
    "    'Puerto Rican': 'Latin American',\n",
    "    'Traditional': 'Other',\n",
    "    'JuiceAndSmoothie': 'Juice and Smoothies',\n",
    "    'Juice Bars & Smoothies': 'Juice and Smoothies',\n",
    "    'Sushi Bar': 'Japanese',\n",
    "    'American (Traditional)': 'American',\n",
    "    'Sports Bar': 'Other',\n",
    "    'Thali': 'Indian',\n",
    "    'Bolivian': 'Latin American',\n",
    "    'Ameican': 'American',\n",
    "    'European: Other': 'European',\n",
    "    'Haitian': 'Caribbean',\n",
    "    'Regalos y flores': 'Other',\n",
    "    'Nigerian': 'African',\n",
    "    'Balkan': 'European',\n",
    "    'Chilean': 'Latin American',\n",
    "    'Som Tum': 'Thai',\n",
    "    'Crepe or Creperie': 'French',\n",
    "    'Steakhouse': 'American',\n",
    "    'Farmacia': 'Other',\n",
    "    'Mercado Express': 'Other',\n",
    "    'Especialidades': 'Other',\n",
    "    'Snack': 'Other',\n",
    "    'Frozen Yogurt': 'Desserts',\n",
    "    'Smoothies': 'Juice and Smoothies',\n",
    "    'Ice cream': 'Desserts',\n",
    "    'Sandwiches/ Salads': 'Salads',\n",
    "    'Czech': 'European',\n",
    "    'Friterie': 'American',\n",
    "    'Frozen Food': 'Other',\n",
    "    'Sopas e Caldos': 'Chinese',\n",
    "    'Local Eats': 'Other',\n",
    "    'FriedRice': 'Asian',\n",
    "    'Assorted Stores': 'Other'\n",
    "}\n",
    "\n",
    "# Map the cuisines to categories based on the dictionary\n",
    "df_req['category_1'] = df_req['category'].map(cuisine_to_category)\n",
    "# Replace NaN values with 'Other'\n",
    "df_req['category_1'] = df_req['category_1'].fillna('Other')\n",
    "\n",
    "\n",
    "\n",
    "(df_req['category_1'].unique())\n",
    "\n",
    "# def extract_cuisine_name(categories):\n",
    "#     if isinstance(categories, str):  # Check if categories is not NaN\n",
    "#         cuisine_list = [\"American\",\"Asian\",\"Italian\", \"Chinese\", \"Japanese\", \"Mexican\",\n",
    "#                         \"Indian\", \"Thai\", \"French\", \"German\",\"African\",\"Spanish\", \"Greek\", \"Middle Eastern\",\n",
    "#                         \"Korean\", \"Vietnamese\", \"Brazilian\", \"Turkish\", \"Moroccan\",\"Caribbean\",\n",
    "#                         \"Desserts\",\"Coffee\",\"Pizza\",\"Mediterranean\",\"Sandwich\",\"Juice\",\"Burgers\",\"Salads\",\"Ice cream\",\"BBQ\"]\n",
    "\n",
    "#         for cuisine in cuisine_list:\n",
    "#             if cuisine in categories:\n",
    "#                 return cuisine\n",
    "            \n",
    "#     return \"Other\"\n",
    "\n",
    "# df_req['category_1'] = df_req['category'].apply(extract_cuisine_name)\n",
    "\n",
    "\n",
    "df_req[df_req['category_1']=='Other']\n",
    "\n",
    "# Get unique categories\n",
    "unique_categories = len(df_req['category_1'].unique())\n",
    "unique_categories1 = df_req['category_1'].unique()\n",
    "print(\"Unique Categories:\", unique_categories)\n",
    "\n",
    "# Fill null values with random value\n",
    "df_req['zip_code'].fillna('11111', inplace=True)\n",
    "# Extract substring before hyphen for valid zip codes\n",
    "df_req['zip_code'] = df_req['zip_code'].apply(lambda x: x.split('-')[0] if '-' in x else x)\n",
    "\n",
    "import re\n",
    "# Replace invalid zip codes with '11111'\n",
    "invalid_zip_mask = df_req['zip_code'].apply(lambda x: bool(re.match(r'^\\d{5}(-\\d{4})?$', str(x))) == False)\n",
    "df_req.loc[invalid_zip_mask, 'zip_code'] = '11111'\n",
    "\n",
    "df_req\n",
    "\n",
    "category_frequency = df_req.groupby(['zip_code', 'category']).size().reset_index(name='count')\n",
    "# Sort the DataFrame in descending order based on 'count'\n",
    "category_frequency_sorted = category_frequency.sort_values(by=['count'], ascending=[False])\n",
    "category_frequency_sorted\n",
    "\n",
    "# Fill NaN values in 'score' and 'ratings' columns with the mean value\n",
    "mean_score = df_req['score'].mean()\n",
    "mean_ratings = df_req['ratings'].mean()\n",
    "df_req['score'].fillna(mean_score, inplace=True)\n",
    "df_req['ratings'].fillna(mean_ratings, inplace=True)\n",
    "\n",
    "# Calculate the weighted average rating\n",
    "df_req['weighted_rating'] = df_req['score'] * df_req['ratings']\n",
    "\n",
    "# Group by zipcode and category and calculate the sum of weighted ratings and total ratings\n",
    "grouped = df_req.groupby(['zip_code', 'category_1']).agg({'weighted_rating': 'sum', 'ratings': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the weighted average rating\n",
    "grouped['weighted_average_rating'] = grouped['weighted_rating'] / grouped['ratings']\n",
    "\n",
    "# Display the new dataset\n",
    "grouped\n",
    "\n",
    "\n",
    "# Find the highest average rating\n",
    "highest_avg = grouped['weighted_average_rating'].idxmax()\n",
    "highest_category = grouped.loc[highest_avg, 'category_1']\n",
    "highest_zip = grouped.loc[highest_avg, 'zip_code']\n",
    "highest_rating = grouped.loc[highest_avg, 'weighted_average_rating']\n",
    "\n",
    "# Find the least average rating\n",
    "least_avg = grouped['weighted_average_rating'].idxmin()\n",
    "least_category = grouped.loc[least_avg, 'category_1']\n",
    "least_zip = grouped.loc[least_avg, 'zip_code']\n",
    "least_rating = grouped.loc[least_avg, 'weighted_average_rating']\n",
    "\n",
    "print(\"Highest Average Rating:\")\n",
    "print(\"Category:\", highest_category)\n",
    "print(\"Zip Code:\", highest_zip)\n",
    "print(\"Weighted Average Rating:\", highest_rating)\n",
    "\n",
    "print(\"\\nLeast Average Rating:\")\n",
    "print(\"Category:\", least_category)\n",
    "print(\"Zip Code:\", least_zip)\n",
    "print(\"Weighted Average Rating:\", least_rating)\n",
    "\n",
    "\n",
    "# Filter the dataset for the \"Indian\" category\n",
    "indian_data = grouped[grouped['category_1'] == 'Indian']\n",
    "\n",
    "# Calculate the weighted average rating for Indian category\n",
    "indian_weighted_avg = indian_data['weighted_average_rating'].values[0]\n",
    "\n",
    "print(\"Weighted Average Rating for Indian Category:\", indian_weighted_avg)\n",
    "\n",
    "\n",
    "final =grouped[['zip_code','category_1','weighted_average_rating']]\n",
    "final.to_csv(\"restaurant_grouped.csv\",index =False)\n",
    "\n",
    "final\n",
    "\n",
    "grouped[grouped['category_1']=='Other']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'y' is your target variable\n",
    "class_counts = df_req['category_1'].value_counts()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Class Distribution Imbalance')\n",
    "plt.show()\n",
    "\n",
    "# Second approach\n",
    "\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Load the original CSV file\n",
    "csv_file_path = r\"C:\\Professional\\MS\\SHU\\Dissertation\\Input_data\\restaurants.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path,encoding ='utf-8')\n",
    "\n",
    "#Use only records without null values\n",
    "df = df.dropna()\n",
    "\n",
    "# List of categories to be renamed to 'Asian'\n",
    "asian_keywords = ['Japanese', 'Chinese', 'Vietnamese', 'Thai', 'Korean']\n",
    "\n",
    "# List of categories to be renamed to 'Italian'\n",
    "italian_keywords = ['Pizza']\n",
    "\n",
    "# List of categories to be renamed to 'American'\n",
    "american_keywords = ['Burger', 'Sandwich', 'Burgers']\n",
    "\n",
    "# Custom function to rename categories\n",
    "def rename_category(row):\n",
    "    for keyword in asian_keywords:\n",
    "        if keyword in row:\n",
    "            return 'Asian'\n",
    "    for keyword in italian_keywords:\n",
    "        if keyword in row:\n",
    "            return 'Italian'\n",
    "    for keyword in american_keywords:\n",
    "        if keyword in row:\n",
    "            return 'American'\n",
    "    return row\n",
    "\n",
    "# Apply the custom function to the 'category' column\n",
    "df['category'] = df['category'].apply(rename_category)  \n",
    "\n",
    "# List of keywords to extract\n",
    "keywords_to_extract = ['American','Mexican','Asian','Italian']\n",
    "\n",
    "# Create a new column to store the extracted keywords\n",
    "df['Extracted_Category'] = ''\n",
    "\n",
    "# Loop through the rows and extract the keyword if present in 'category_1'\n",
    "for index, row in df.iterrows():\n",
    "    for keyword in keywords_to_extract:\n",
    "        if keyword in row['category']:\n",
    "            df.at[index, 'category_1'] = keyword\n",
    "            break  # No need to continue checking other keywords\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Keeping only records with the extracted categories\n",
    "df_req= df[df['category_1'] != ''].dropna()\n",
    "\n",
    "# Get unique categories\n",
    "unique_categories = len(df['category_1'].unique())\n",
    "unique_categories1 = df['category_1'].unique()\n",
    "print(\"Unique Categories:\", unique_categories, ' ', unique_categories1)\n",
    "\n",
    "# Fill null values with random value\n",
    "df_req['zip_code'].fillna('11111', inplace=True)\n",
    "# Extract substring before hyphen for valid zip codes\n",
    "df_req['zip_code'] = df_req['zip_code'].apply(lambda x: x.split('-')[0] if '-' in x else x)\n",
    "\n",
    "import re\n",
    "# Replace invalid zip codes with '11111'\n",
    "invalid_zip_mask = df_req['zip_code'].apply(lambda x: bool(re.match(r'^\\d{5}(-\\d{4})?$', str(x))) == False)\n",
    "df_req.loc[invalid_zip_mask, 'zip_code'] = '11111'\n",
    "\n",
    "df_req\n",
    "\n",
    "# Fill NaN values in 'score' and 'ratings' columns with the mean value\n",
    "mean_score = df_req['score'].mean()\n",
    "mean_ratings = df_req['ratings'].mean()\n",
    "df_req['score'].fillna(mean_score, inplace=True)\n",
    "df_req['ratings'].fillna(mean_ratings, inplace=True)\n",
    "\n",
    "# Calculate the weighted average rating\n",
    "df_req['weighted_rating'] = df_req['score'] * df_req['ratings']\n",
    "\n",
    "# Group by zipcode and category and calculate the sum of weighted ratings and total ratings\n",
    "grouped = df_req.groupby(['zip_code', 'category_1']).agg({'weighted_rating': 'sum', 'ratings': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the weighted average rating\n",
    "grouped['weighted_average_rating'] = grouped['weighted_rating'] / grouped['ratings']\n",
    "\n",
    "# Display the new dataset\n",
    "grouped\n",
    "\n",
    "# Find the highest average rating\n",
    "highest_avg = grouped['weighted_average_rating'].idxmax()\n",
    "highest_category = grouped.loc[highest_avg, 'category_1']\n",
    "highest_zip = grouped.loc[highest_avg, 'zip_code']\n",
    "highest_rating = grouped.loc[highest_avg, 'weighted_average_rating']\n",
    "\n",
    "# Find the least average rating\n",
    "least_avg = grouped['weighted_average_rating'].idxmin()\n",
    "least_category = grouped.loc[least_avg, 'category_1']\n",
    "least_zip = grouped.loc[least_avg, 'zip_code']\n",
    "least_rating = grouped.loc[least_avg, 'weighted_average_rating']\n",
    "\n",
    "print(\"Highest Average Rating:\")\n",
    "print(\"Category:\", highest_category)\n",
    "print(\"Zip Code:\", highest_zip)\n",
    "print(\"Weighted Average Rating:\", highest_rating)\n",
    "\n",
    "print(\"\\nLeast Average Rating:\")\n",
    "print(\"Category:\", least_category)\n",
    "print(\"Zip Code:\", least_zip)\n",
    "print(\"Weighted Average Rating:\", least_rating)\n",
    "\n",
    "final =grouped[['zip_code','category_1','weighted_average_rating']]\n",
    "final.to_csv(\"restaurant_grouped.csv\",index =False)\n",
    "\n",
    "grouped\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
